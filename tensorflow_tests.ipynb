{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from Object_Detection import ObjectDectection\n",
    "from yolo_helper import GeneratorMultipleOutputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n02165456', 'n02226429', 'n01644373', 'n02279972', 'n01632458', 'n02256656', 'n01774384', 'n01770393']\n"
     ]
    }
   ],
   "source": [
    "reduced_dataset_folder = '/home/usuario/repos/Object_Localization/challenge_dataset_v3'\n",
    "train_folder = reduced_dataset_folder + '/images/train'\n",
    "val_folder = reduced_dataset_folder + '/images/val'\n",
    "annotations_dict_train = np.load(reduced_dataset_folder+'/annotations_train.npy').flat[0]\n",
    "annotations_dict_val = np.load(reduced_dataset_folder+'/annotations_val.npy').flat[0]\n",
    "classes = list(annotations_dict_train.keys())\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_CLASSES = 8\n",
    "IMAGE_H = 32\n",
    "IMAGE_W = 32\n",
    "GRID_H = IMAGE_H // 32\n",
    "GRID_W = IMAGE_W // 32\n",
    "NUMBER_OF_BBOXES = 1\n",
    "object_detection = ObjectDectection(NUMBER_OF_CLASSES, IMAGE_H, IMAGE_W, NUMBER_OF_BBOXES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2400 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 60\n",
    "train_generator = GeneratorMultipleOutputs(annotations_dict_train, \n",
    "                            train_folder, batch_size, classes = classes,\n",
    "                            target_size=(IMAGE_H,IMAGE_W),\n",
    "                            GRID_H = GRID_H,\n",
    "                            GRID_W = GRID_W, \n",
    "                            flip_horizontal = True, \n",
    "                            flip_vertical = True,\n",
    "                            crop_per=0.2\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 480 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = GeneratorMultipleOutputs(annotations_dict_val, \n",
    "                            val_folder, batch_size, classes = classes,\n",
    "                            target_size=(IMAGE_H,IMAGE_W),\n",
    "                            GRID_H = GRID_H,\n",
    "                            GRID_W = GRID_W,\n",
    "                            flip_horizontal = True, \n",
    "                            flip_vertical= True,\n",
    "                            crop_per=0.2\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "start_bbox_idx = 1 + len(classes)\n",
    "\n",
    "def bounding_box_mse(y_true, y_pred):\n",
    "    indexes = tf.where(K.equal(y_true[:,:,:,:,0], K.ones_like(y_true[:,:,:,:,0])))\n",
    "    y_true_pos = tf.gather_nd(y_true, indexes)[:,start_bbox_idx:start_bbox_idx+4]\n",
    "    y_pred_pos = tf.gather_nd(y_pred, indexes)[:,start_bbox_idx:start_bbox_idx+4]\n",
    "    return K.mean(K.square(y_pred_pos - y_true_pos), axis=-1)\n",
    "\n",
    "        \n",
    "    \n",
    "def categorical_cross_entropy_loss(y_true, y_pred):\n",
    "    indexes = tf.where(K.equal(y_true[:,:,:,:,0], K.ones_like(y_true[:,:,:,:,0])))\n",
    "    y_true_pos = tf.gather_nd(y_true, indexes)[:, start_classes_idx:start_classes_idx+NUMBER_OF_CLASSES]\n",
    "    y_pred_pos = tf.gather_nd(y_pred, indexes)[:, start_classes_idx:start_classes_idx+NUMBER_OF_CLASSES]\n",
    "    return K.mean(K.categorical_crossentropy(y_true_pos, K.softmax(y_pred_pos)))\n",
    "        \n",
    "    \n",
    "\n",
    "def object_bin_cross_entropy_loss(y_true, y_pred):\n",
    "    indexes = tf.where(K.equal(y_true[:,:,:,:,0], K.ones_like(y_true[:,:,:,:,0])))\n",
    "    y_true_pos = tf.gather_nd(y_true, indexes)\n",
    "    y_pred_pos = tf.gather_nd(y_pred, indexes)\n",
    "    return K.mean(K.mean(K.binary_crossentropy(y_true_pos[:,:1], K.sigmoid(y_pred_pos[:,:1])), axis=-1))\n",
    "    \n",
    "    \n",
    "def no_object_bin_cross_entropy_loss(y_true, y_pred):\n",
    "    indexes_neg = tf.where(K.equal(y_true[:,:,:,:,0], K.zeros_like(y_true[:,:,:,:,0])))\n",
    "    y_true_pos = tf.gather_nd(y_true, indexes_neg)\n",
    "    y_pred_pos = tf.gather_nd(y_pred, indexes_neg)\n",
    "    return K.mean(K.mean(K.binary_crossentropy(y_true_pos[:,:1], K.sigmoid(y_pred_pos[:,:1])), axis=-1))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, y_true = next(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = object_detection.model.predict_on_batch(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_0 = bounding_box_mse(tf.constant(y_true, dtype='float32'), tf.constant(y_pred, dtype='float32'))\n",
    "#out_1 = focal_loss_2(tf.constant(y_true, dtype='float32'), tf.constant(y_pred, dtype='float32'))\n",
    "#out_2 = focal_loss_3(tf.constant(y_true, dtype='float32'), tf.constant(y_pred, dtype='float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60,)\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "with sess.as_default():\n",
    "    print(out_0.eval().shape)\n",
    "    \n",
    "# 0.086642854\n",
    "# 0.08664659"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[1.]]]]])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[[1.]]]]]), array([[[[[0.9]]]]], dtype=float32))"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3862943571198905\n"
     ]
    }
   ],
   "source": [
    "def cross_entropy(predictions, targets, epsilon=1e-12):\n",
    "    \"\"\"\n",
    "    Computes cross entropy between targets (encoded as one-hot vectors)\n",
    "    and predictions. \n",
    "    Input: predictions (N, k) ndarray\n",
    "           targets (N, k) ndarray        \n",
    "    Returns: scalar\n",
    "    \"\"\"\n",
    "    predictions = np.clip(predictions, epsilon, 1. - epsilon)\n",
    "    N = predictions.shape[0]\n",
    "    ce = -np.sum(targets*np.log(predictions+1e-9))/N\n",
    "    return ce\n",
    "\n",
    "predictions = np.array([[0.25]])\n",
    "targets = np.array([[1]])\n",
    "x = cross_entropy(predictions, targets)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
